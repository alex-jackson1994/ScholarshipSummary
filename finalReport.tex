\documentclass[]{article}
\usepackage{cite,url}
%opening
\title{Analysing the Error of Predictions of the Pairwise Sequentially Markovian Coalescent (PSMC) Model}
\author{Shaun D. Barker, Alex L. Jackson}
\begin{document}

\maketitle

\begin{abstract}

\end{abstract}
\section{Introduction}
\section{Background Material}
\subsection{PSMC}
The Pairwise Sequentially Markovian Coalescent (PSMC) model \cite{li2011inference} is a model for predicting population histories based on the whole genome of a single individual. PSMC uses the heterozygousity of the genome to estimate where recombination events have occurred in the genome. These estimates are completed using a Hidden Markov Model where the hidden state is the time at which recombination events have occurred and the observed variable is the heterozygousity of a bin of 100 base pairs. Using these estimates of the times of recombination events allows PSMC to then construct a population estimate over a period of time. 

\section{Methods}
\subsection{Generating Simulated Data} %This almost falls under background material
We used genomic data simulated by msHOT-lite \cite{mshotlite} to analyse the error of the PSMC model. msHOT-lite is a modification by Li upon the genetic simulation software msHOT \cite{hellenthal2007mshot} which is itself a modification upon the original software package ms \cite{hudson2002generating}. msHOT-lite allows us to simulate the genome of an individual subject to a specified number of base pairs, chromosomes, mutation rate, recombination rate and population history. 
An example of a msHOT-lite call is: 

\verb|msHOT-lite 2 1 -t 60000 -r 10000 1000000 -eN 1 2 -eN 2 4 -l >output.ms| 
This call simulates a diploid genome with a single chromosome (\verb|msHOT-lite 2 1|). Then \verb|-t 60000| sets the parameter $\theta$ to 60000 where $\theta=4N_0\mu$, where $\mu$ is the neutral mutation rate for the entire genome and $N_0$ is the initial population size. Then \verb|-r 10000 1000000| sets the parameter $\rho$ to 10000 and the number of base pairs per chromosome to 1000000 where $\rho=4N_0r$ and $r$ is the recombination probability per generation. Lastly \verb|-eN 1 2 -eN 2 4| introduces two population changes in the species history, firstly at time 1 (which is $4N_0$ generations ago) the population is set to 2 (which is $2\times4N_0$) and then at time 2 (which is $2\times4N_0$ generations ago) the population is set to 4 (which is $4\times4N_0$).

msHOT-lite can output in several different formats, we used the \verb|-l| switch that outputs a text file containing a list of coordinates for heterozygous base pairs, we denoted these as having the \verb|.ms| file extension. The PSMC software package \cite{li2011inference} provides a Perl script called \verb|ms2psmcfa.pl| that converts from this file format into the input format \verb|.psmcfa| that PSMC takes as an input. The file format \verb|.psmcfa| is a FASTA-like format, each sequence is given a header line started by \verb|>| and the sequence is recorded on 80 character long lines afterwards. Each character on these lines represents a bin of 100 base pairs and whether a heterozygous base pair exists within that bin.

\subsection{Processing Real Data}
Working with real data requires a different approach to create the required \verb|.psmcfa| input file. For our work we were given a steppe bison genome in a binary alignment format (\verb|.bam|) file (the format of which was first described in \cite{li2009sequence}) as well as a reference bison genome as a FASTA (\verb|.fa|) file. The first step was to create a consensus sequence in the FASTQ (\verb|.fq|) format from this data using the Samtools suite (we used version 1.3). This was accomplished using the following commands:
\begin{verbatim}
./samtools mpileup -EA -Q20 -C50 -u -f refBison.fasta SteppeBison.bam \ 
./bcftools call -c \
./vcfutils.pl vcf2fq \
gzip> mpileupedSteppeBison.fq.gz
\end{verbatim}
This command has four parts, firstly it performs a pileup where the steppe bison data is compared to the reference bison data. The consensus sequence is then called from the data using bcftools. Then the output from that data is converted into FASTQ format using vcfutils. Lastly the whole thing is compressed using gzip. 

Once in this format we can use a utility provided with PSMC to create the \verb|.psmcfa| input file. PSMC includes the utility \verb|fq2psmcfa| that converts compressed or uncompressed FASTQ format files into the required \verb|.psmcfa| input file.

\subsection{Setting up experiments} %thats an atrocious title
Every PSMC run requires only a \verb|.psmcfa| input file, this gives us an obvious choice to where we should modify files for our experiments. 

\subsubsection{Splitting the Data}
The first experiment we considered was the effect of splitting the contiguous sequences into many smaller sequences. This was accomplished using the Python script \verb|binarySplitPsmcfaPrint.py|. This script breaks each sequence in a \verb|.psmcfa| file into two equal length sequences. We did this recursively taking a simulated genome is splitting it up until the genome contained many more sequences than it initially did. 

\subsubsection{Combining the Data}
The opposite of the previous section, we consider what would happen if we started joined every contig together into a single giant contig. This was achieved using the Bash script \verb|combinePsmcfa.sh|. 

\subsubsection{Deleting Data}
Another experiment we considered was deleting random data from the sequence. This was achieved using the Python script \verb|removeRandomPartsFromPsmcfa.py| which looped through the \verb|.psmcfa| file removing random lines from the file without deleting entire contigs. Physically a line in a \verb|.psmcfa| file represents 8000 base pairs, since a line is at most 80 characters long and each character is a bin of 100 base pairs. This was repeated, removing 10\%, 20\%, ... 90\% of the genome each time and running PSMC on the result using the Bash script \verb|partRemovalRepeated.sh|.

\subsubsection{Time Intervals}
PSMC makes population history estimates over a variety of times which are split up into discrete intervals. The intervals are split between the present and a maximum estimation time $T_{max}$ which is chosen by PSMC. PSMC takes a pattern of intervals in the form of a string '$a$*$b$' where this would be $a$ intervals of length $b$, note that these lengths are in a log scale. By default PSMC assumes a pattern of intervals '4+5*3+4' which is 4 intervals of length 1 followed by 5 intervals of length 3 followed by 4 intervals of length 1 again. For our experiments we ignored any intervals of length other than 1 and considered only splitting into equal length intervals of '10', '20', '30' and '40'.

\subsubsection{Contig Length in Real Data}
One difference between the simulated and the real data is the number of base pairs that are in each contig. Where simulated data has a constant number specified in the \verb|ms| command, real data has a number of varied lengths. The script \verb|summaryStatistics.py| takes a \verb|.psmcfa| file as an input and prints a tab delimited table of the minimum, maximum, median and of base pairs in each contig in the given file as well as the total number of base pairs in the entire file. We used this when considering the effect of breaking up the data had on the error.

\subsection{Running PSMC}
PSMC requires a \verb|.psmcfa| file as input for the genetic data and can take several switches that modify default behaviour. We used the \verb|-p| switch to specify different time intervals as discussed above. PSMC was run using the following command
\begin{verbatim}
		./psmc -p '40*1' inputFile.psmcfa > outputFile.psmc
\end{verbatim}
which performs PSMC on the given input file using 40 equal length time intervals.

\subsubsection{PSMC Output Files (.psmc)}
The output files generated by PSMC are a tab delimited text format where the first two characters on each line defines what values are on the line. The output files always contain a header which gives some information on the format and then the estimates for each iteration of the Baum-Welch algorithm used in PSMC. The last table contains the estimates from the final iteration, this is the data we used for our analysis. The last table can be extracted as a tab delimited table using the script \verb|removeDataFromPSMC.sh|. This script takes a \verb|.psmc| output file as its input and then outputs the final table in the file as a tab delimited text file.

\subsection{Automating the simulations}
%See \verb|runSimulations.sh|

Simulating the data through to obtaining the PSMC results is a multi-step process that can be automated to save time and effort. The script \verb|runSimulations.sh| completes the entire process autonomously, after some minor initial tweaking by the user. The user should modify the variable \verb|simulationName|, at the top of the file, which gives a prefix to every file and folder used in the script, and modify the \verb|msHOT-lite| function call, which dictates the population demography. After these changes are made the script will run through and simulate the genome, split the genome, usually up to 1024 times, generate the PSMC input files, run PSMC and finally write the output to a file. These files are then organised into folders based on the run parameters and compressed into a single archive. Analysis can then be easily performed on the files and their respective simulated results.

\subsection{ANALYSE THIS!}

\section{Results}
\section{Discussion}
\section{Conclusion}
\bibliographystyle{plain}
\bibliography{bibliography}{}

\end{document}
